{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append(\"../dlutils\")\n",
    "import importlib\n",
    "import model\n",
    "import dataset\n",
    "import train\n",
    "import loss\n",
    "importlib.reload(model)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(train)\n",
    "importlib.reload(loss)\n",
    "from dataset import load_fashion_mnist_dataset\n",
    "from train import train_3ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader, test_loader = load_fashion_mnist_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An MLP with one single hidden layer\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_hiddens):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.hidden = nn.Sequential(nn.Linear(in_features, num_hiddens), nn.ReLU())\n",
    "        self.out = nn.Linear(num_hiddens, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.out(self.hidden(self.flatten(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 28*28\n",
    "out_features = 10\n",
    "num_hiddens = 128\n",
    "mlp = MLP(in_features, out_features, num_hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(mlp.parameters(),lr=0.1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, training loss 0.658942, training accuracy 0.734367, testing loss 0.658942, testing accuracy 0.734367\n",
      "epoch 1, training loss 0.811372, training accuracy 0.674067, testing loss 0.811372, testing accuracy 0.674067\n",
      "epoch 2, training loss 0.777586, training accuracy 0.709717, testing loss 0.777586, testing accuracy 0.709717\n",
      "epoch 3, training loss 0.681550, training accuracy 0.723633, testing loss 0.681550, testing accuracy 0.723633\n",
      "epoch 4, training loss 0.705151, training accuracy 0.718550, testing loss 0.705151, testing accuracy 0.718550\n",
      "epoch 5, training loss 0.645114, training accuracy 0.740267, testing loss 0.645114, testing accuracy 0.740267\n",
      "epoch 6, training loss 0.998616, training accuracy 0.601083, testing loss 0.998616, testing accuracy 0.601083\n",
      "epoch 7, training loss 0.809609, training accuracy 0.687083, testing loss 0.809609, testing accuracy 0.687083\n",
      "epoch 8, training loss 0.706393, training accuracy 0.729017, testing loss 0.706393, testing accuracy 0.729017\n",
      "epoch 9, training loss 0.837415, training accuracy 0.638400, testing loss 0.837415, testing accuracy 0.638400\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_3ch(mlp, loss, num_epochs,train_loader, optimizer,\\\n",
    "         test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "mytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
