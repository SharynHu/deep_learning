{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is bias?\n",
    "\n",
    "Bias is the difference between the average prediction of our model and the correct value which we are trying to predict. **Model with high bias pays very little attention to the training data and oversimplifies the model. It always leads to high error on training and test data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is variance?\n",
    "\n",
    "Variance is the variability of model prediction for a given data point or a value which tells us spread of our data. Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasnâ€™t seen before. As a result, such models perform very well on training data but has high error rates on test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to evaluate the variance of a model/estimator?\n",
    "\n",
    "It's only possible to calculate the true variance if you have a set of every possible randomly-drawn data set $ğ·$ (or an equivalent p.d.f) and every single $ğ‘¥$ input possible (or an equivalent p.d.f). This is the result of the mathematical definition of the variance of a learning model/algorithm: $ğ¸_ğ‘¥[ğ¸_ğ·[ğ‘”^ğ‘‘(ğ‘¥)âˆ’\\overline{g}(ğ‘¥)]]$, where $ğ‘‘\\inğ·$. \n",
    "\n",
    "This will obviously never happen. The only time when you can exactly calculate the variance is when you create your own data. Even then, both $ğ·$ and $ğ‘¥$ will likely be infinite (if you have any continuous predictors or outputs), so you'll just be approximating the variance by drawing large samples from $ğ·$ and $ğ‘¥$.\n",
    "\n",
    "### Bootstrap\n",
    "\n",
    "This statistical technique consists in generating samples of size B (called bootstrap samples) from an initial dataset of size N by randomly **drawing with replacement** B observations (there may contain duplicates in each subset).\n",
    "\n",
    "Under certain circumstances, bootstrap samples can be considered as representative and independent samples of the true data distribution (almost i.i.d. samples).\n",
    "\n",
    "This requires:\n",
    "\n",
    "1. the size N of the initial dataset should be large enough to capture most of the complexity of the underlying distribution so that sampling from the dataset is a good approximation of sampling from the real distribution (representativity).\n",
    "2. the size N of the dataset should be large enough compared to the size B of the bootstrap samples so that samples are not too much correlated (independence).\n",
    "\n",
    "### Approximate model variance via bootstrap\n",
    "\n",
    "We can use bootstrapping to generate several bootstrap samples that can be considered as being â€œalmost-representativeâ€ and â€œalmost-independentâ€ (almost i.i.d. samples). These bootstrap samples will allow us to approximate the variance of the estimator, by evaluating its value for each of them.\n",
    "![](./bootstrap_estimator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance tradeoff\n",
    "Low variance (high bias) algorithms turn to be less complex, with simple or rigid underlying structure. These models include linear or parametric algorithms such as regression and naive Bayes.\n",
    "On the other hand, low bias (high variance) algorithms turn to be more complex, with a flexible underlying structure. These models include non-linear or non-parametric algorithms such as decision trees and nearest neighbors.\n",
    "This tradeoff in complexity is thereâ€™s a tradeoff in bias and variance an algorithm cannot simultaneously be more complex and less complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
