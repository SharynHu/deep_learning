{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Dropout is a regularization method to avoid overfitting.\n",
    "\n",
    "![](./dropout.png)\n",
    "\n",
    "$r_j^{(l)}\\sim Bernoulli(p)$ where $p$ represents the probability of activating a certain neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout during training\n",
    "\n",
    "1. a mask $u$ is randomly generated to determine which neurons are activated while which are frozen. After applying the mask, we get a subnetwork;\n",
    "2. use a minibatch to do feedforward propagation, calculate the loss and do backward propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout during testing\n",
    "\n",
    "1. Do feedforward propagation for the whole network;\n",
    "2. for each neuron, the output need be rescaled,\n",
    "$$a =a*p$$\n",
    "to make the expected output unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspectives on dropout\n",
    "\n",
    "### Hinton's view on dropout\n",
    "\n",
    "Hinton sees the final model as an ensemble of subnets.\n",
    "\n",
    "All subnets shares weights as each subnet inherit a subset of the weights of the whole network. Most subnets are not trained explictly, but weight sharing makes the remianing subnets has a good weight setting.\n",
    "\n",
    "Assume for each subnet, the objective function is $J(\\theta, u)$, then the final objective for this whole ensemble model is  the expected loss \n",
    "$$E_{u\\sim q(u)}J(u, \\theta)$$\n",
    "\n",
    "\n",
    "**Dropout is an approximation to geometric model averaing.**\n",
    "\n",
    "### Dropout on feature selection\n",
    "\n",
    "Dropout encourages the network to learn from features not as effective as the other neuronsâ€™ features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append(\"../dlutils\")\n",
    "import importlib\n",
    "import model\n",
    "import dataset\n",
    "import train\n",
    "import loss\n",
    "importlib.reload(model)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(train)\n",
    "importlib.reload(loss)\n",
    "from dataset import load_fashion_mnist_dataset\n",
    "from train import train_3ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_loader,test_loader = load_fashion_mnist_dataset(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Dropout\n",
    "\n",
    "p1_zeroed, p2_zeroed = 0.2, 0.5\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(), torch.nn.Linear(784, 256), torch.nn.ReLU(),\n",
    "            # Add a dropout layer after the first fully connected layer\n",
    "            Dropout(p1_zeroed),\n",
    "            torch.nn.Linear(256, 256), torch.nn.ReLU(),\n",
    "            # Add a dropout layer after the second fully connected layer\n",
    "            Dropout(p2_zeroed), \n",
    "            torch.nn.Linear(256, 10))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def train(self):\n",
    "        for subnet in self.modules():\n",
    "            if isinstance(subnet, Dropout):\n",
    "                subnet.train = True\n",
    "            \n",
    "    def eval(self):\n",
    "        for subnet in self.modules():\n",
    "            if isinstance(subnet, Dropout):\n",
    "                subnet.train = False\n",
    "\n",
    "net = Net()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, training loss 0.003167, training accuracy 0.695267, testing loss 0.003320, testing accuracy 0.689200\n",
      "epoch 1, training loss 0.002960, training accuracy 0.719917, testing loss 0.003045, testing accuracy 0.712200\n",
      "epoch 2, training loss 0.002778, training accuracy 0.737333, testing loss 0.002902, testing accuracy 0.730300\n",
      "epoch 3, training loss 0.002679, training accuracy 0.750467, testing loss 0.002807, testing accuracy 0.743100\n",
      "epoch 4, training loss 0.002594, training accuracy 0.760617, testing loss 0.002679, testing accuracy 0.757700\n",
      "epoch 5, training loss 0.002465, training accuracy 0.774533, testing loss 0.002602, testing accuracy 0.756700\n",
      "epoch 6, training loss 0.002407, training accuracy 0.779550, testing loss 0.002487, testing accuracy 0.778600\n",
      "epoch 7, training loss 0.002366, training accuracy 0.782867, testing loss 0.002488, testing accuracy 0.776300\n",
      "epoch 8, training loss 0.002284, training accuracy 0.792217, testing loss 0.002411, testing accuracy 0.780700\n",
      "epoch 9, training loss 0.002247, training accuracy 0.796383, testing loss 0.002452, testing accuracy 0.784200\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.1\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from train import train_3ch\n",
    "train_3ch(net, loss, num_epochs, train_loader, optimizer=trainer, test_loader=test_loader, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torchtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
